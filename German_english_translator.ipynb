{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4DMCthMoSBGk/XHpHMxuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melaan99/Stroke-Prediction/blob/main/German_english_translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Técnicas Avanzadas de Inteligencia Artificial**\n",
        "\n",
        "**Tema: Traducción de texto del alemán al inglés utilizando redes codificador-decodificador con atención.**\n",
        "\n",
        "\n",
        "Autor: Lina María Ferrer Rodríguez linamfr@uci.cu\n",
        "\n",
        "Centro de Estudios de Matemática Computacional *texto en cursiva*\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "C15a5OBLn2Z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Qué es la traducción automática neuronal?\n",
        "\n",
        "\"La traducción automática es la tarea de convertir automáticamente texto fuente en una lengua a texto en otra lengua. Dada una secuencia de texto en una lengua de partida, no existe una única traducción óptima de ese texto a otra lengua. Esto se debe a la ambigüedad y flexibilidad naturales del lenguaje humano. Esto hace que el reto de la traducción automática sea difícil, quizá uno de los más difíciles de la inteligencia artificial\".\n",
        "\n",
        "- \"Machine Learning Mastery\" por Jason Brownlee, Ph.D.\n",
        "\n",
        "Inicialmente, los problemas de traducción automática (TA) se afrontaban utilizando enfoques estadísticos, basados principalmente en las probabilidades de Bayes. Pero cuando las redes neuronales se hicieron más potentes y populares, los investigadores empezaron a explorar las capacidades de esta tecnología y se encontraron nuevas soluciones. Es lo que se denomina traducción automática neuronal (NMT, en inglés, Neural Machine Translation).\n",
        "\n",
        "\n",
        "# ¿Que son las redes codificador-decodificador con atención?\n",
        "\n",
        "NMT es un problema en el que se procesa una secuencia de entrada para producir una secuencia de salida, es decir, un problema de secuencia a secuencia (seq2seq).\n",
        "De lo anterior se deduce que la TNM es un problema en el que procesamos una secuencia de entrada para producir una secuencia de salida, es decir, un problema de secuencia a secuencia (seq2seq). Concretamente, el tipo many-to-many, con una secuencia de varios elementos tanto en la entrada como en la salida. Existen varias arquitecturas para resolver problemas de seq2seq en el procesamiento del lenguaje natural, una de las más utilizadas es precisamente las redes codificador-decodificador con atención.\n",
        "\n",
        "Las redes codificador-decodificador son una arquitectura de redes neuronales en las que, el codificador transforma una secuencia de entrada en un vector de características y el decodificador utiliza ese vector de características para generar una secuencia de salida. Las redes codificador-decodificador con atención son una variante de las redes codificador-decodificador que utilizan un mecanismo de atención para mejorar la calidad de las traducciones automáticas y otras tareas de procesamiento del lenguaje natural.\n",
        "\n",
        "\n",
        "#Codificador:\n",
        "\n",
        "El codificador es un tipo de red que \"codifica\", es decir, obtiene o extrae características de unos datos de entrada dados. Lee la secuencia de entrada y resume la información en algo llamado vectores de estado interno o vector de contexto (en el caso de la red LSTM, se llaman vectores de estado oculto y de estado de celda). Normalmente se descartan las salidas del codificador y sólo conservamos los estados internos. Este vector de contexto pretende contener toda la información de todos los elementos de entrada para ayudar al descodificador a realizar predicciones precisas. El estado oculto y el estado de las neuronas de la red se pasan al decodificador como entrada.\n",
        "\n",
        "#Decodificador:\n",
        "\n",
        "Un decodificador es algo que \"decodifica\", interpreta el vector de contexto obtenido del codificador. El vector de contexto de la última neurona del codificador es la entrada a la primera neurona de la red del decodificador. Utilizando estos estados iniciales, el descodificador empieza a generar la secuencia de salida, y estas salidas también se tienen en cuenta para futuras predicciones. Una pila de varias unidades LSTM en la que cada una predice una salida (digamos y_hat) en un paso de tiempo t.Cada unidad recurrente acepta un estado oculto de la unidad anterior y produce una salida, así como su propio estado oculto para pasar a lo largo de la red posterior.\n",
        "\n",
        "\n",
        "#Mecanismo de atención\n",
        "\n",
        "\n",
        "La atención es una mejora de la red existente de modelos secuencia a secuencia que aborda esta limitación. La sencilla razón por la que se denomina \"atención\" es por su capacidad para obtener significado en las secuencias. En primer lugar, funciona proporcionando un contexto más ponderado o más significado desde el codificador al decodificador y un mecanismo de aprendizaje en el que el decodificador puede interpretar que, en realidad, presta más \"atención\" a la red de codificación posterior cuando predice las salidas en cada paso temporal de la secuencia de salida.\n",
        "\n",
        "\n",
        "Podemos considerar que, al utilizar el mecanismo de atención, existe la idea de liberar la arquitectura codificador-decodificador existente de la representación interna de longitud corta fija del texto. Esto se consigue manteniendo las salidas intermedias de la red LSTM codificadora, que corresponden a un determinado nivel de significación, de cada paso de la secuencia de entrada y, al mismo tiempo, entrenando al modelo para que aprenda y preste atención selectiva a estos elementos intermedios y los relacione después con elementos de la secuencia de salida.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fRx3kjIKn-Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Encoder-Decoder-model-with-Attention-Mechanism.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "XgFzMDGdY-eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el ejemplo que se estará trabajando se utilizarán estas redes para la **traducción** de texto del **alemán** al **inglés**.\n"
      ],
      "metadata": {
        "id": "ilVG6POdDyrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model,load_model, model_from_json\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle as pkl\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NFlyDAD7Dvjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adquicisión de los datos\n",
        "El conjunto de datos lingüísticos a trabajar está disponible en :\n",
        "http://www.manythings.org/anki/\n",
        "\n",
        "Este sitio contiene un conjunto de datos de numerosos idiomas y su traducción al inglés. Se puede descargar cualquier conjunto de datos de idiomas según preferencias y comodidad. En este caso, se utilizará el conjunto de datos German - English que contiene 38696"
      ],
      "metadata": {
        "id": "QzNcdV5yEKWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "url='https://drive.google.com/file/d/1qKlylT8bEjuYP8iuoqqytyY6h1bvZYs1/view?usp=drive_link'\n",
        "file_path = \"/content/drive/My Drive/técnicas avanzadas de inteligenci artificial/deu.txt\"\n",
        "\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = file.read()\n"
      ],
      "metadata": {
        "id": "oN2NAuJWD2vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento\n",
        "Los datos importados se trata de un archivo de texto sin procesar. Para trabajar con el mismo, es necesario limpiarlo y transformarlo. Se separarán las frases en alemán e inglés y se formará una lista con ellas, continuando con su almacenamiento en un dataframe para que resulte fácil reutilizarlo de nuevo."
      ],
      "metadata": {
        "id": "2zsiBZJIGpOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformación de los datos\n",
        "\n",
        "uncleaned_data_list = data.split('\\n')\n",
        "len(uncleaned_data_list)\n",
        "uncleaned_data_list = uncleaned_data_list[:38695]\n",
        "len(uncleaned_data_list)\n",
        "english_word = []\n",
        "german_word = []\n",
        "cleaned_data_list = []\n",
        "for word in uncleaned_data_list:\n",
        "  english_word.append(word.split('\\t')[:-1][0])\n",
        "  german_word.append(word.split('\\t')[:-1][1])\n",
        "language_data = pd.DataFrame(columns=['English','German'])\n",
        "language_data['English'] = english_word\n",
        "language_data['German'] = german_word\n",
        "language_data.to_csv('language_data.csv', index=False)"
      ],
      "metadata": {
        "id": "MQ_hcgFUGfIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_data.head()\n",
        "english_text = language_data['English'].values\n",
        "german_text = language_data['German'].values\n",
        "len(english_text), len(german_text)"
      ],
      "metadata": {
        "id": "7eaVjh3BNgGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza de los datos\n",
        "\n",
        "#convertir a minúscula\n",
        "english_text_ = [x.lower() for x in english_text]\n",
        "german_text_ = [x.lower() for x in german_text]\n",
        "\n",
        "\n",
        "#eliminar las comas invertidas\n",
        "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
        "german_text_ = [re.sub(\"'\",'',x) for x in german_text_]\n",
        "def remove_punc(text_list):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  removed_punc_text = []\n",
        "  for sent in text_list:\n",
        "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
        "    removed_punc_text.append(' '.join(sentance))\n",
        "  return removed_punc_text\n",
        "english_text_ = remove_punc(english_text_)\n",
        "german_text_ = remove_punc(german_text_)\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "removed_digits_text = []\n",
        "for sent in english_text_:\n",
        "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_text.append(' '.join(sentance))\n",
        "english_text_ = removed_digits_text\n",
        "\n",
        "\n",
        "# eliminar caracteres de las frases en alemán\n",
        "german_text_ = [re.sub(\"[^a-zA-Z0-9öÖäÄüÜß@\\\\s]\",\"\",x) for x in german_text_]\n",
        "\n",
        "\n",
        "# eliminar espacios al principio y al final de las frases\n",
        "english_text_ = [x.strip() for x in english_text_]\n",
        "german_text_ = [x.strip() for x in german_text_]\n",
        "\n",
        "\n",
        "# Añadir las etiquetas \"start\" y \"end\" a las frases en alemán\n",
        "german_text_ = [\"start \" + x + \" end\" for x in german_text_]\n",
        "german_text_[0], english_text_[0]"
      ],
      "metadata": {
        "id": "jwtZVogeOvIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparación de los datos para el modelo:\n",
        "\n",
        "Se dividen los datos con una proporción de 0,1, X_train y Y_train serán el conjunto de entrenamiento, X_test y Y_test serán los conujntos de prueba.\n"
      ],
      "metadata": {
        "id": "zWHhN2yFdDQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = english_text_\n",
        "Y = german_text_\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1)\n",
        "\n",
        "#determinar la longitud máxima de las frases en ambos idiomas\n",
        "def Max_length(data):\n",
        "  max_length_ = max([len(x.split(' ')) for x in data])\n",
        "  return max_length_\n",
        "\n",
        "#Training data\n",
        "max_length_english = Max_length(X_train)\n",
        "max_length_german = Max_length(y_train)\n",
        "\n",
        "#Test data\n",
        "max_length_english_test = Max_length(X_test)\n",
        "max_length_german_test = Max_length(y_test)\n",
        "max_length_german, max_length_english"
      ],
      "metadata": {
        "id": "l5w_axWrQrvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toquenización\n",
        "\n",
        "La tokenización es un paso importante en la construcción de estas redes ya que permite que el modelo trabaje con una representación numérica del texto en lugar del texto en sí, lo que facilita el procesamiento y la manipulación de los datos. Además, la tokenización permite que el modelo maneje correctamente los problemas de variabilidad del lenguaje, como la aparición de diferentes formas de una misma palabra o la presencia de palabras desconocidas en el texto. Una forma de hacerlo es utilizar Tokenizer proporcionado por la biblioteca keras-preprocessing.\n"
      ],
      "metadata": {
        "id": "ku7wmRtiRged"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "englishTokenizer = Tokenizer()\n",
        "englishTokenizer.fit_on_texts(X_train)\n",
        "Eword2index = englishTokenizer.word_index\n",
        "vocab_size_source = len(Eword2index) + 1\n",
        "\n",
        "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
        "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')\n",
        "\n",
        "germanTokenizer = Tokenizer()\n",
        "germanTokenizer.fit_on_texts(y_train)\n",
        "Gword2index = germanTokenizer.word_index\n",
        "vocab_size_target = len(Gword2index) + 1\n",
        "\n",
        "y_train = germanTokenizer.texts_to_sequences(y_train)\n",
        "y_train = pad_sequences(y_train, maxlen=max_length_german, padding='post')\n",
        "y_test = germanTokenizer.texts_to_sequences(y_test)\n",
        "y_test = pad_sequences(y_test, maxlen = max_length_german, padding='post')\n",
        "\n",
        "vocab_size_source, vocab_size_target"
      ],
      "metadata": {
        "id": "R5Hy23_ERkKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], y_train[0]"
      ],
      "metadata": {
        "id": "SmG3ZX0vSVwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bahdanau attention\n",
        "\n",
        "Bahdanau Attention es un tipo de mecanismo de atención utilizado en las redes neuronales para el procesamiento del lenguaje natural. Este mecanismo permite que el modelo se centre en diferentes partes de la secuencia de entrada durante la generación de la secuencia de salida, lo que mejora la calidad de las traducciones automáticas y otras tareas de procesamiento del lenguaje natural.\n",
        "\n",
        "La clase AttentionLayer que se muestra a continuación es la implementación del mecanismo de atención de Bahdanau, la mismo, está disponible en:\n",
        "https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py"
      ],
      "metadata": {
        "id": "1d061zCjznN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "logger = tf.get_logger()\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
        "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            logger.debug(\"Running energy computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "\n",
        "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "\n",
        "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            logger.debug(\"Running attention vector computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "\n",
        "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
        "\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        # we don't maintain states between steps when computing attention\n",
        "        # attention is stateless, so we're passing a fake state for RNN step function\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "metadata": {
        "id": "19IAZIWg8TEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construcción del modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "D_4WlFUAh_aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "latent_dim = 500\n",
        "# Codificador\n",
        "encoder_inputs = Input(shape=(max_length_english,))\n",
        "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
        "#LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "#LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "#LSTM 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# configuración del decodificador\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "#LSTM usando encoder_states como estado inicial\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        " # Capa de atención\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concatenar la salida de atención y la salida LSTM del decodificador\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Capa densa\n",
        "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Definición del modelo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "plot_model(model, to_file='train_model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "OEDCPqmH4qsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xGrS248R8z_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo\n",
        "\n",
        "Primeramente se definen algunos callbacks para que sea mas fácil la visualización y evaluación del modelo en el futuro.\n",
        "\n",
        "Para entrenar este modelo se utiliza la técnica \"Teacher Forcing\". \"Teacher Forcing\" es una técnica de entrenamiento utilizada en las redes neuronales para el procesamiento del lenguaje natural, especialmente en tareas de generación de secuencias, como la traducción automática o la generación de texto. Durante el entrenamiento, se utiliza la salida correcta (o la \"respuesta del profesor\") como entrada en la siguiente etapa del modelo. Esto significa que, en cada paso del modelo, se utiliza la palabra o secuencia de palabras correctas en lugar de la palabra o secuencia de palabras generadas por el modelo.\n"
      ],
      "metadata": {
        "id": "ifx-RTNkhEqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:],\n",
        "                    epochs=10,\n",
        "                    callbacks=[es],\n",
        "                    batch_size=512,\n",
        "                    validation_data = ([X_test, y_test[:,:-1]],           y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "id": "6UDC3B_FhCnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el aprendizaje automático, una época (en inglés, \"epoch\") se refiere a una iteración completa a través de un conjunto de datos de entrenamiento durante el entrenamiento de un modelo. En otras palabras, una época significa que todos los ejemplos en el conjunto de datos de entrenamiento han sido vistos una vez por el modelo.\n",
        "\n",
        "Durante cada época, el modelo procesa cada ejemplo de entrenamiento en el conjunto de datos, realiza una predicción y luego ajusta los pesos de las conexiones neuronales para minimizar la función de pérdida. Después de que se hayan procesado todos los ejemplos en el conjunto de datos de entrenamiento, se completa una época.\n",
        "\n",
        "El número de épocas que se deben utilizar durante el entrenamiento depende de la complejidad del modelo y del conjunto de datos de entrenamiento. En este caso por cuestiones de rendimiento se utilizaron solo 10 epochs.\n",
        "\n",
        "A continuación se podrá visualizar utilizando pyplot como se va minimizando la pérdida."
      ],
      "metadata": {
        "id": "SBQvz5vNlcfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualización de pérdida:\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "DIDdyC46hRA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para salvar el modelo\n",
        "model_json = model.to_json()\n",
        "with open(\"NMT_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serializar pesos a HDF5\n",
        "model.save_weights(\"NMT_model_weight.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "A5C4OmPghT3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar la arquitectura del modelo y asignar los pesos\n",
        "json_file = open('NMT_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model_loaded = model_from_json(loaded_model_json, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "# cargar pesos en el nuevo modelo\n",
        "model_loaded.load_weights(\"NMT_model_weight.h5\")"
      ],
      "metadata": {
        "id": "9jcwHLmihkzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.summary()"
      ],
      "metadata": {
        "id": "3Li47rrQvX9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de inferencia\n",
        "El modelo de inferencia, se trata de un modelo que deduce las propiedades aprendidas en la fase de entrenamiento para predecir nuevas secuencias. En contraposición con el modelo de entrenamiento, este, utiliza los parámetros ya ajustados para hacer predicciones del conjunto de datos de prueba o en tiempo real\n",
        "\n"
      ],
      "metadata": {
        "id": "COJg1AGr9RWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim=500\n",
        "# inferencia del codificador\n",
        "encoder_inputs = model_loaded.input[0]  #loading encoder_inputs\n",
        "encoder_outputs, state_h, state_c = model_loaded.layers[6].output #cargar salidas_codificador\n",
        "#print(salidas_codificador.forma)\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "# inferencia del decodificador\n",
        "# Abajo los tensores contendrán los estados del paso de tiempo anterior\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(32,latent_dim))\n",
        "\n",
        "# Obtener los embeddins de la secuencia decodificadora\n",
        "decoder_inputs = model_loaded.layers[3].output\n",
        "\n",
        "dec_emb_layer = model_loaded.layers[5]\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Para predecir la siguiente palabra de la secuencia, establece los estados iniciales a los estados del paso de tiempo anterior\n",
        "decoder_lstm = model_loaded.layers[7]\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#inferencia de atención\n",
        "attn_layer = model_loaded.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "concate = model_loaded.layers[9]\n",
        "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# Una capa densa softmax para generar prob dist. sobre el vocabulario objetivo\n",
        "decoder_dense = model_loaded.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Modelo final de decodificador\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "ItsPZvZc88N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción\n"
      ],
      "metadata": {
        "id": "ynE4UXWA9Yye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "   # Codificación de la entrada como vectores de estado.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "   # Generaración de la secuencia objetivo vacía de longitud 1\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Elección de la palabra \"inicio\" como primera palabra de la secuencia objetivo\n",
        "    target_seq[0, 0] = Gword2index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Muestra de un token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0:\n",
        "          break\n",
        "        else:\n",
        "          sampled_token = Mindex2word[sampled_token_index]\n",
        "\n",
        "          if(sampled_token!='end'):\n",
        "              decoded_sentence += ' '+sampled_token\n",
        "\n",
        "              # Condición de salida: o alcanza la longitud máxima o encuentra la palabra de parada.\n",
        "              if (sampled_token == 'end' or len(decoded_sentence.split()) >= (26-1)):\n",
        "                  stop_condition = True\n",
        "\n",
        "          # Actualizar la secuencia objetivo (de longitud 1)\n",
        "          target_seq = np.zeros((1,1))\n",
        "          target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "          # Actualizar estados internos\n",
        "          e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "KxG0ps6tvhpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Formar un vocabulario inverso:\n",
        "Eindex2word = englishTokenizer.index_word\n",
        "Mindex2word = germanTokenizer.index_word"
      ],
      "metadata": {
        "id": "cYv5JTDU9eZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alguna transformación antes de dar una cadena a la función:\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=Gword2index['start']) and i!=Gword2index['end']):\n",
        "        newString=newString+Mindex2word[i]+' '\n",
        "    return newString\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+Eindex2word[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "ikJf9OUf9kBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(\"Review:\",seq2text(X_test[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(X_test[i].reshape(1,6)))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "C54iBqrT9wsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}